{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import pandas as pd\n",
    "from src.data import load_scaler\n",
    "from src.cluster import load_kmeans_model\n",
    "from src.eval import final_run\n",
    "from src.model import Autoencoder\n",
    "#import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_autoencoder_model(autoencoder_path: str) -> object:\n",
    "    \"\"\"\n",
    "    Load a saved autoencoder model from disk.\n",
    "    \"\"\"\n",
    "    dir_path = os.path.dirname(os.path.abspath(__file__))\n",
    "    full_path = os.path.join(dir_path, autoencoder_path)\n",
    "    \n",
    "    # Load the model\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fa36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for cluster 0 with threshold 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helgamariamagnusdottir/Documents/dtu/comp_tools/data_science/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/helgamariamagnusdottir/Documents/dtu/comp_tools/data_science/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/helgamariamagnusdottir/Documents/dtu/comp_tools/data_science/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "final_run() got an unexpected keyword argument 'threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m     X_cluster = X_scaled[cluster_labels == i]\n\u001b[32m     20\u001b[39m     y_cluster = y[cluster_labels == i]\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mfinal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_cluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Split X_scaled based on cluster labels\u001b[39;00m\n\u001b[32m     24\u001b[39m X_cluster_1 = X_scaled[cluster_labels == \u001b[32m1\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: final_run() got an unexpected keyword argument 'threshold'"
     ]
    }
   ],
   "source": [
    "thresholds = [0.5, 0.5, 0.5, 0.5]\n",
    "tune_data_path='../data/tune_data.csv'\n",
    "model_paths = ['../checkpoints'\n",
    "#def final_run(thresholds=[0.5, 0.5, 0.5, 0.5], tune_data_path='../data/tune_data.csv'):\n",
    "\n",
    "df = pd.read_csv(tune_data_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=[\"Class\"]).values\n",
    "y = df[\"Class\"].values \n",
    "\n",
    "scaler = load_scaler()\n",
    "X_scaled = scaler.transform(X)   \n",
    "\n",
    "kmeans_model = load_kmeans_model()\n",
    "cluster_labels = kmeans_model.predict(X_scaled)\n",
    "\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    print(f\"Evaluating for cluster {i} with threshold {threshold}\")\n",
    "    X_cluster = X_scaled[cluster_labels == i]\n",
    "    \n",
    "    # load weights for cluster i\n",
    "    weights_path = f'../checkpoints/autoencoder_cluster_{i}.pt'\n",
    "    weights = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # TODO: Put the correct weights into the model\n",
    "    model = Autoencoder(in_dim=X_scaled.shape[1], hidden_units=64, latent_features=2, num_layers=1)\n",
    "    model.load_state_dict(weights)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # No gradients needed\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(X_cluster_tensor)\n",
    "        # Reconstruction error per sample\n",
    "        reconstruction_error = F.mse_loss(\n",
    "            reconstructed,\n",
    "            X_cluster_tensor,\n",
    "            reduction='none'\n",
    "        ).mean(dim=1)     # mean across features for each sample\n",
    "\n",
    "# reconstruction_error is a tensor of shape (num_samples_in_cluster,)\n",
    "print(reconstruction_error)\n",
    "\n",
    "\n",
    "\n",
    "    # calc reconstruction error for X_cluster\n",
    "    # classify based on threshold\n",
    "\n",
    "\n",
    "\n",
    "# Split X_scaled based on cluster labels\n",
    "X_cluster_1 = X_scaled[cluster_labels == 1]\n",
    "\n",
    "print(X_cluster_1.shape, X_scaled.shape)\n",
    "\n",
    "#X_clusters = [X_scaled[cluster_labels == i] for i in range(kmeans_model.n_clusters)]\n",
    "\n",
    "# Tekur punkt og hendir í rétt módel\n",
    "\n",
    "\n",
    "    # assignar módel\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
