{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ed242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import pandas as pd\n",
    "from src.data import load_scaler\n",
    "from src.cluster import load_kmeans_model\n",
    "from src.model import AutoEncoder\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fa36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for cluster 0 with threshold 0.5\n",
      "  Cluster 0 - n=442\n",
      "    Accuracy : 0.8824\n",
      "    Precision: 0.9560\n",
      "    Recall   : 0.7716\n",
      "    F1       : 0.8539\n",
      "Evaluating for cluster 1 with threshold 0.5\n",
      "  Cluster 1 - n=180\n",
      "    Accuracy : 0.9111\n",
      "    Precision: 0.7609\n",
      "    Recall   : 0.8750\n",
      "    F1       : 0.8140\n",
      "Evaluating for cluster 2 with threshold 0.5\n",
      "  Cluster 2 - n=1120\n",
      "    Accuracy : 0.5312\n",
      "    Precision: 0.2375\n",
      "    Recall   : 0.9701\n",
      "    F1       : 0.3816\n",
      "Evaluating for cluster 3 with threshold 0.5\n",
      "  Cluster 3 - n=718\n",
      "    Accuracy : 0.9485\n",
      "    Precision: 0.7339\n",
      "    Recall   : 0.9091\n",
      "    F1       : 0.8122\n",
      "\n",
      "=== Overall metrics ===\n",
      "Accuracy   : 0.7439\n",
      "Error rate : 0.2561\n",
      "Precision  : 0.4307\n",
      "Recall     : 0.8720\n",
      "F1-score   : 0.5766\n",
      "Confusion matrix [ [TN FP], [FN TP] ]:\n",
      "[[1401  567]\n",
      " [  63  429]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunna/Desktop/dtu/year2/autumn/Data Science/project/.venv/lib/python3.14/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/sunna/Desktop/dtu/year2/autumn/Data Science/project/.venv/lib/python3.14/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.5, 0.5, 0.5, 0.5]   # threshold for each cluster\n",
    "tune_data_path='../data/tune_data.csv'\n",
    "\n",
    "# -- Load data --\n",
    "df = pd.read_csv(tune_data_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=[\"Class\"]).values\n",
    "y = df[\"Class\"].values \n",
    "\n",
    "# -- Scale & cluster data --\n",
    "scaler = load_scaler()\n",
    "X_scaled = scaler.transform(X)   \n",
    "\n",
    "kmeans_model = load_kmeans_model()\n",
    "cluster_labels = kmeans_model.predict(X_scaled)\n",
    "\n",
    "# Array for global predictions\n",
    "y_pred = np.zeros_like(y)\n",
    "cluster_metrics = {}\n",
    "\n",
    "for i, threshold in enumerate(thresholds):      \n",
    "    print(f\"Evaluating for cluster {i} with threshold {threshold}\")\n",
    "    \n",
    "    # mask for points in cluster i\n",
    "    mask = (cluster_labels == i)\n",
    "\n",
    "    X_cluster = X_scaled[mask]\n",
    "    y_cluster = y[mask]\n",
    "\n",
    "    # Initialize model, load weights and set to eval mode\n",
    "    model = AutoEncoder.from_pretrained(cluster_id=i, models_dir='../models')\n",
    "\n",
    "    # Forward pass and compute reconstruction error\n",
    "    X_cluster_t = torch.tensor(X_cluster, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(X_cluster_t)          # out is a dict: {'z': ..., 'x_hat': ...}\n",
    "        reconstructed = out['x_hat']      # (batch_size, in_dim)\n",
    "        reconstruction_error = F.mse_loss(\n",
    "            reconstructed,\n",
    "            X_cluster_t,\n",
    "            reduction='none'\n",
    "        ).mean(dim=1)  # mean over features â†’ one error per sample\n",
    "    \n",
    "    # -- Thresholding --\n",
    "    reconstruction_error_np = reconstruction_error.cpu().numpy()\n",
    "    pred_cluster = (reconstruction_error_np > threshold).astype(int)\n",
    "\n",
    "    # Put the predictions back into the global array\n",
    "    y_pred[mask] = pred_cluster\n",
    "\n",
    "    acc_c = accuracy_score(y_cluster, pred_cluster)\n",
    "    prec_c = precision_score(y_cluster, pred_cluster, zero_division=0)\n",
    "    rec_c = recall_score(y_cluster, pred_cluster, zero_division=0)\n",
    "    f1_c = f1_score(y_cluster, pred_cluster, zero_division=0)\n",
    "\n",
    "    cluster_metrics[i] = {\n",
    "        \"accuracy\": acc_c,\n",
    "        \"precision\": prec_c,\n",
    "        \"recall\": rec_c,\n",
    "        \"f1\": f1_c,\n",
    "        \"n_samples\": len(y_cluster)\n",
    "    }\n",
    "\n",
    "    print(f\"  Cluster {i} - n={len(y_cluster)}\")\n",
    "    print(f\"    Accuracy : {acc_c:.4f}\")\n",
    "    print(f\"    Precision: {prec_c:.4f}\")\n",
    "    print(f\"    Recall   : {rec_c:.4f}\")\n",
    "    print(f\"    F1       : {f1_c:.4f}\")\n",
    "\n",
    "# --- Global metrics over all clusters ---\n",
    "acc = accuracy_score(y, y_pred)\n",
    "prec = precision_score(y, y_pred, zero_division=0)\n",
    "rec = recall_score(y, y_pred, zero_division=0)\n",
    "f1 = f1_score(y, y_pred, zero_division=0)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "error_rate = 1.0 - acc\n",
    "\n",
    "print(\"\\n=== Overall metrics ===\")\n",
    "print(f\"Accuracy   : {acc:.4f}\")\n",
    "print(f\"Error rate : {error_rate:.4f}\")\n",
    "print(f\"Precision  : {prec:.4f}\")\n",
    "print(f\"Recall     : {rec:.4f}\")\n",
    "print(f\"F1-score   : {f1:.4f}\")\n",
    "print(\"Confusion matrix [ [TN FP], [FN TP] ]:\")\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1b7bd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AutoEncoder:\n\tsize mismatch for encoder.2.weight: copying a param with shape torch.Size([8, 64]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for encoder.2.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([64, 8]) from checkpoint, the shape in current model is torch.Size([64, 2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[32m      2\u001b[39m model = AutoEncoder(in_dim=X_scaled.shape[\u001b[32m1\u001b[39m], hidden_units=\u001b[32m64\u001b[39m, latent_features=\u001b[32m2\u001b[39m, num_layers=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Evaluate model on X_cluster\u001b[39;00m\n\u001b[32m      6\u001b[39m X_cluster_t = torch.tensor(X_cluster, dtype=torch.float32)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/dtu/year2/autumn/Data Science/project/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for AutoEncoder:\n\tsize mismatch for encoder.2.weight: copying a param with shape torch.Size([8, 64]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for encoder.2.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([64, 8]) from checkpoint, the shape in current model is torch.Size([64, 2])."
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoEncoder(in_dim=X_scaled.shape[1], hidden_units=64, latent_features=2, num_layers=1)\n",
    "model.load_state_dict(weights)\n",
    "\n",
    "# Evaluate model on X_cluster\n",
    "X_cluster_t = torch.tensor(X_cluster, dtype=torch.float32)\n",
    "model.eval()\n",
    "\n",
    "# No gradients needed\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(X_cluster_t)\n",
    "    \n",
    "\n",
    "\n",
    "# # Reconstruction error per sample\n",
    "reconstruction_error = F.mse_loss(\n",
    "        reconstructed,                  \n",
    "        X_cluster_t,                  \n",
    "        reduction='none'\n",
    "    ).mean(dim=1)   # mean across features for each sample  \n",
    "with torch.no_grad():\n",
    "    outputs = model(X_t)\n",
    "    X_hat = outputs[\"x_hat\"]\n",
    "    errors = torch.mean((X_hat - X_t)**2, dim=1).cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
